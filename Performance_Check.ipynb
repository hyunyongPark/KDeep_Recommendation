{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ca41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import ast\n",
    "import dgl\n",
    "import argparse\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torchtext\n",
    "import torchtext.legacy as torchtext\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "\n",
    "import layers\n",
    "import sampler as sampler_module\n",
    "import evaluation\n",
    "\n",
    "from scipy import spatial\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e10706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7249e7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b63ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_param_num(model):\n",
    "    '''\n",
    "    check num of model parameters\n",
    "\n",
    "    :model: pytorch model object\n",
    "    :return: int\n",
    "    '''\n",
    "    param_num = 0 \n",
    "    for parameter in model.parameters():\n",
    "        param_num += parameter.shape[0]\n",
    "    return param\n",
    "\n",
    "def node_to_item(nodes, id_dict, cateogry_dict):\n",
    "    '''\n",
    "    Transform node id to real item id\n",
    "\n",
    "    :items: node id list\n",
    "    :id_dict: {node id: item category id}\n",
    "    :category_dict: {item category id: real item id}\n",
    "    '''\n",
    "    ids = [id_dict[i] for i in nodes]\n",
    "    ids = [cateogry_dict[i] for i in ids]   \n",
    "    return ids\n",
    "\n",
    "def get_blocks(seeds, item_ntype, textset, sampler):\n",
    "    blocks = []\n",
    "    for seed in seeds:\n",
    "        block = sampler.get_block(seed, item_ntype, textset)\n",
    "        blocks.append(block)\n",
    "    return blocks\n",
    "\n",
    "def get_all_emb(gnn, seed_array, textset, item_ntype, neighbor_sampler, batch_size, device='cuda'):\n",
    "    seeds = torch.arange(seed_array.shape[0]).split(batch_size)\n",
    "    testset = get_blocks(seeds, item_ntype, textset, neighbor_sampler)\n",
    "    gnn = gnn.to(device)\n",
    "    gnn.eval()\n",
    "    with torch.no_grad():\n",
    "        h_item_batches = []\n",
    "        for blocks in testset:\n",
    "            for i in range(len(blocks)):\n",
    "                blocks[i] = blocks[i].to(device)\n",
    "\n",
    "            h_item_batches.append(gnn.get_repr(blocks))\n",
    "        h_item = torch.cat(h_item_batches, 0)\n",
    "    return h_item\n",
    "    \n",
    "def item_by_user_batch(graph, user_ntype, item_ntype, user_to_item_etype, weight, batch_size, k):\n",
    "    '''\n",
    "    :return: list of interacted node ids by every users \n",
    "    '''\n",
    "    rec_engine = LatestNNRecommender(\n",
    "        user_ntype, item_ntype, user_to_item_etype, weight, batch_size)\n",
    "\n",
    "    graph_slice = graph.edge_type_subgraph([rec_engine.user_to_item_etype])\n",
    "    n_users = graph.number_of_nodes(rec_engine.user_ntype)  # 유저개수\n",
    "    latest_interactions = dgl.sampling.select_topk(graph_slice, k, rec_engine.timestamp, edge_dir='out')\n",
    "    user, latest_items = latest_interactions.all_edges(form='uv', order='srcdst')\n",
    "    # user, latest_items = (k * n_users)\n",
    "\n",
    "    items_df = pd.DataFrame({'user': user.numpy(), 'item': latest_items.numpy()}).groupby('user')\n",
    "    items_batch = [items_df.get_group(i)['item'].values for i in np.unique(user)]\n",
    "    return items_batch\n",
    "\n",
    "def prec(recommendations, ground_truth):\n",
    "    n_users, n_items = ground_truth.shape\n",
    "    K = recommendations.shape[1]\n",
    "    user_idx = np.repeat(np.arange(n_users), K)\n",
    "    item_idx = recommendations.flatten()\n",
    "    relevance = ground_truth[user_idx, item_idx].reshape((n_users, K))\n",
    "    hit = relevance.any(axis=1).mean()\n",
    "    return hit\n",
    "\n",
    "class LatestNNRecommender(object):\n",
    "    def __init__(self, user_ntype, item_ntype, user_to_item_etype, timestamp, batch_size):\n",
    "        self.user_ntype = user_ntype\n",
    "        self.item_ntype = item_ntype\n",
    "        self.user_to_item_etype = user_to_item_etype\n",
    "        self.batch_size = batch_size\n",
    "        self.timestamp = timestamp\n",
    "\n",
    "    def recommend(self, full_graph, K, h_user, h_item):\n",
    "        \"\"\"\n",
    "        Return a (n_user, K) matrix of recommended items for each user\n",
    "        \"\"\"\n",
    "        graph_slice = full_graph.edge_type_subgraph([self.user_to_item_etype])\n",
    "        n_users = full_graph.number_of_nodes(self.user_ntype)\n",
    "        latest_interactions = dgl.sampling.select_topk(graph_slice, K, self.timestamp, edge_dir='out')\n",
    "        user, latest_items = latest_interactions.all_edges(form='uv', order='srcdst')\n",
    "        # each user should have at least one \"latest\" interaction\n",
    "        assert torch.equal(user, torch.arange(n_users))\n",
    "\n",
    "        recommended_batches = []\n",
    "        user_batches = torch.arange(n_users).split(self.batch_size)\n",
    "        for user_batch in user_batches:\n",
    "            latest_item_batch = latest_items[user_batch]\n",
    "            dist = h_item[latest_item_batch] @ h_item.t()\n",
    "\n",
    "            # 기존 인터랙션 삭제\n",
    "            # 이 부분을 주석처리했음\n",
    "            # for i, u in enumerate(user_batch.tolist()):\n",
    "            #     interacted_items = full_graph.successors(u, etype=self.user_to_item_etype)\n",
    "            #     dist[i, interacted_items] = -np.inf\n",
    "            recommended_batches.append(dist.topk(K, 1)[1])\n",
    "\n",
    "        recommendations = torch.cat(recommended_batches, 0)\n",
    "        return recommendations\n",
    "\n",
    "\n",
    "def evaluate_nn(dataset, h_item, k, batch_size):\n",
    "    g = dataset['train-graph']\n",
    "    val_matrix = dataset['val-matrix'].tocsr()\n",
    "    test_matrix = dataset['test-matrix'].tocsr()\n",
    "    item_texts = dataset['item-texts']\n",
    "    user_ntype = dataset['user-type']\n",
    "    item_ntype = dataset['item-type']\n",
    "    user_to_item_etype = dataset['user-to-item-type']\n",
    "    timestamp = dataset['timestamp-edge-column']\n",
    "\n",
    "    rec_engine = LatestNNRecommender(\n",
    "        user_ntype, item_ntype, user_to_item_etype, timestamp, batch_size)\n",
    "\n",
    "    recommendations = rec_engine.recommend(g, k, None, h_item).cpu().numpy()\n",
    "    return prec(recommendations, val_matrix)\n",
    "\n",
    "class PinSAGEModel(nn.Module):\n",
    "    def __init__(self, full_graph, ntype, textsets, hidden_dims, n_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.proj = layers.LinearProjector(full_graph, ntype, textsets, hidden_dims)\n",
    "        self.sage = layers.SAGENet(hidden_dims, n_layers)\n",
    "        self.scorer = layers.ItemToItemScorer(full_graph, ntype)\n",
    "\n",
    "    def forward(self, pos_graph, neg_graph, blocks):\n",
    "        h_item = self.get_repr(blocks)\n",
    "        pos_score = self.scorer(pos_graph, h_item)\n",
    "        neg_score = self.scorer(neg_graph, h_item)\n",
    "        return (neg_score - pos_score + 1).clamp(min=0)\n",
    "\n",
    "    def get_repr(self, blocks):\n",
    "        h_item = self.proj(blocks[0].srcdata)\n",
    "        h_item_dst = self.proj(blocks[-1].dstdata)\n",
    "        return h_item_dst + self.sage(blocks, h_item)\n",
    "        \n",
    "def load_model(data_dict, device, lr, hidden_dims, num_layers, save_path):\n",
    "    gnn = PinSAGEModel(data_dict['graph'], data_dict['item_ntype'], data_dict['textset'], hidden_dims, num_layers).to(device)\n",
    "    opt = torch.optim.Adam(gnn.parameters(), lr=lr)\n",
    "    checkpoint = torch.load(save_path + '.pt', map_location=\"cuda:1\")\n",
    "    gnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    return gnn\n",
    "\n",
    "def prepare_dataset(data_dict):\n",
    "    g = data_dict['graph']\n",
    "    item_texts = data_dict['item_texts']\n",
    "    user_ntype = data_dict['user_ntype']\n",
    "    item_ntype = data_dict['item_ntype']\n",
    "\n",
    "    # Assign user and movie IDs and use them as features (to learn an individual trainable\n",
    "    # embedding for each entity)\n",
    "    g.nodes[user_ntype].data['id'] = torch.arange(g.number_of_nodes(user_ntype))\n",
    "    g.nodes[item_ntype].data['id'] = torch.arange(g.number_of_nodes(item_ntype))\n",
    "    data_dict['graph'] = g\n",
    "\n",
    "    # Prepare torchtext dataset and vocabulary\n",
    "    if not len(item_texts):\n",
    "        data_dict['textset'] = None\n",
    "    else:\n",
    "        fields = {}\n",
    "        examples = []\n",
    "        for key, texts in item_texts.items():\n",
    "            fields[key] = torchtext.data.Field(include_lengths=True, lower=True, batch_first=True)\n",
    "        for i in range(g.number_of_nodes(item_ntype)):\n",
    "            example = torchtext.data.Example.fromlist(\n",
    "                [item_texts[key][i] for key in item_texts.keys()],\n",
    "                [(key, fields[key]) for key in item_texts.keys()])\n",
    "            examples.append(example)\n",
    "            \n",
    "        textset = torchtext.data.Dataset(examples, fields)\n",
    "        for key, field in fields.items():\n",
    "            field.build_vocab(getattr(textset, key))\n",
    "            #field.build_vocab(getattr(textset, key), vectors='fasttext.simple.300d')\n",
    "        data_dict['textset'] = textset\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "def prepare_dataloader(data_dict, batch_size, \n",
    "                       random_walk_length, random_walk_restart_prob, \n",
    "                       num_random_walks, num_neighbors, num_layers, num_workers):\n",
    "    g = data_dict['graph']\n",
    "    user_ntype = data_dict['user_ntype']\n",
    "    item_ntype = data_dict['item_ntype']\n",
    "    textset = data_dict['textset']\n",
    "    # Sampler\n",
    "    batch_sampler = sampler_module.ItemToItemBatchSampler(\n",
    "        g, user_ntype, item_ntype, batch_size)\n",
    "    neighbor_sampler = sampler_module.NeighborSampler(\n",
    "        g, user_ntype, item_ntype, random_walk_length,\n",
    "        random_walk_restart_prob, num_random_walks, num_neighbors,\n",
    "        num_layers)\n",
    "    collator = sampler_module.PinSAGECollator(neighbor_sampler, g, item_ntype, textset)\n",
    "    dataloader = DataLoader(\n",
    "        batch_sampler,\n",
    "        collate_fn=collator.collate_train,\n",
    "        num_workers=num_workers)\n",
    "\n",
    "    dataloader_test = DataLoader(\n",
    "        torch.arange(g.number_of_nodes(item_ntype)),\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collator.collate_test,\n",
    "        num_workers=num_workers)\n",
    "    dataloader_it = iter(dataloader)\n",
    "\n",
    "    return dataloader_it, dataloader_test, neighbor_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd71525",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./graph_data/kdata_entire9.pkl\"\n",
    "device=\"cuda:1\"\n",
    "save_path=\"./model_first/model_20epoch\"\n",
    "random_walk_length = 2\n",
    "random_walk_restart_prob = 0.5\n",
    "num_random_walks = 10\n",
    "num_neighbors = 10\n",
    "num_layers = 6\n",
    "hidden_dims = 1024\n",
    "batch_size = 64\n",
    "batches_per_epoch = 10000\n",
    "num_epochs = 500\n",
    "num_workers = 0\n",
    "lr = 3e-5\n",
    "eval_epochs = 10\n",
    "save_epochs = 10\n",
    "k = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_path, 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88150e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "        'graph': dataset['train-graph'],\n",
    "        'val_matrix': None,\n",
    "        'test_matrix': None,\n",
    "        'item_texts': dataset['item-texts'],\n",
    "        'testset': dataset['testset'], \n",
    "        'user_ntype': dataset['user-type'],\n",
    "        'item_ntype': dataset['item-type'],\n",
    "        'user_to_item_etype': dataset['user-to-item-type'],\n",
    "        'timestamp': dataset['timestamp-edge-column'],\n",
    "        'user_category': dataset['user-category'], \n",
    "        'item_category': dataset['item-category']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f31bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f'{device}' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cpu':\n",
    "    print('Current using CPUs')\n",
    "else:\n",
    "    print ('Current cuda device ', torch.cuda.current_device()) # check\n",
    "\n",
    "# Dataset\n",
    "data_dict = prepare_dataset(data_dict)\n",
    "dataloader_it, dataloader_test, neighbor_sampler = prepare_dataloader(data_dict, batch_size, \n",
    "                       random_walk_length, random_walk_restart_prob, \n",
    "                       num_random_walks, num_neighbors, num_layers, num_workers)\n",
    "\n",
    "gnn = load_model(data_dict, device, lr, hidden_dims, num_layers, save_path)\n",
    "\n",
    "g = data_dict['graph']\n",
    "item_ntype = data_dict['item_ntype']\n",
    "user_ntype = data_dict['user_ntype']\n",
    "user_to_item_etype = data_dict['user_to_item_etype']\n",
    "timestamp = data_dict['timestamp']\n",
    "nid_uid_dict = {v: k for v, k in enumerate(list(g.ndata['userID'].values())[0].numpy())}\n",
    "nid_wid_dict = {nid.item(): wid.item() for wid, nid in zip(g.ndata['item_id']['item'], g.ndata['id']['item'])}\n",
    "\n",
    "gnn = gnn.to(device)\n",
    "h_item = get_all_emb(gnn, g.ndata['id'][item_ntype], data_dict['textset'], item_ntype, neighbor_sampler, batch_size, device)\n",
    "item_batch = item_by_user_batch(g, user_ntype, item_ntype, user_to_item_etype, timestamp, batch_size, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51c4978",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_data = pd.read_csv(\"KData/rate_data.csv\", index_col=0)\n",
    "rate_data = rate_data.sort_values(by=\"rate\", ascending=False).reset_index(drop=True)\n",
    "rate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f328e648",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_item = rate_data.loc[(rate_data[\"user\"] == user_id), \"item\"].values.tolist()\n",
    "sort_idx = [i for i, x in enumerate(sort_item) if x in list(label)]\n",
    "label = [x for i, x in enumerate(sort_item)if i in sort_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1415be4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0339d",
   "metadata": {},
   "source": [
    "### KNN 방법으로 했을 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3fdf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = 0#[]\n",
    "hitrates = 0\n",
    "users = []\n",
    "num_labels = 0\n",
    "counts_n = 0\n",
    "mean_recall = []\n",
    "k_num = 10\n",
    "\n",
    "model = NearestNeighbors(n_neighbors = k_num, \n",
    "                         metric = 'cosine',\n",
    "                        )#cosine\n",
    "model.fit(h_item.detach().cpu().numpy())\n",
    "for i, nodes in tqdm.tqdm(enumerate(item_batch)):\n",
    "    # 실제 유저 ID 탐색\n",
    "    category = nid_uid_dict[i]\n",
    "    user_id = data_dict['user_category'][category]  # 실제 유저 id\n",
    "    label = data_dict['testset'][user_id]  # 테스트 라벨\n",
    "    users.append(user_id)\n",
    "    item = evaluation.node_to_item(nodes, nid_wid_dict, data_dict['item_category'])  # 와인 ID\n",
    "    label_idx = [i for i, x in enumerate(item) if x in label]  # 라벨 인덱스\n",
    "    #nodes = [x for i, x in enumerate(nodes)if i not in label_idx]  # 라벨 인덱스 미포함 입력 학습용 노드\n",
    "    nodes = [x for i, x in enumerate(nodes)]\n",
    "    h_nodes = h_item[nodes]\n",
    "    h_center = torch.mean(h_nodes, axis=0)  # 중앙 임베딩 \n",
    "    _, topk = model.kneighbors(h_center.detach().cpu().numpy().reshape(1, -1))\n",
    "        \n",
    "    topk = topk[0]\n",
    "    tp = [x for x in label if x in topk]\n",
    "    if not tp:\n",
    "        recalls += 0\n",
    "    else:\n",
    "        mean_recall.append(len(tp)/len(label))\n",
    "        recalls += len(tp)\n",
    "        num_labels += len(label)\n",
    "recall = np.mean(np.array(mean_recall))#recalls / num_labels\n",
    "recall2 = recalls / num_labels\n",
    "print(f'\\tRecall@{k_num}:{recall}')\n",
    "print(f'\\tRecall@{k_num}:{recall2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21db013",
   "metadata": {},
   "outputs": [],
   "source": [
    "hitrates = 0\n",
    "users = []\n",
    "counts_n = 0\n",
    "k_num = 500\n",
    "\n",
    "model = NearestNeighbors(n_neighbors = k_num, \n",
    "                         metric = 'cosine',\n",
    "                        )#cosine\n",
    "model.fit(h_item.detach().cpu().numpy())\n",
    "for i, nodes in tqdm.tqdm(enumerate(item_batch)):\n",
    "    # 실제 유저 ID 탐색\n",
    "    category = nid_uid_dict[i]\n",
    "    user_id = data_dict['user_category'][category]  # 실제 유저 id\n",
    "    label = data_dict['testset'][user_id]  # 테스트 라벨\n",
    "    users.append(user_id)\n",
    "    \n",
    "    item = evaluation.node_to_item(nodes, nid_wid_dict, data_dict['item_category'])  # 와인 ID\n",
    "    label_idx = [i for i, x in enumerate(item) if x in label]  # 라벨 인덱스\n",
    "    nodes = [x for i, x in enumerate(nodes)if i not in label_idx]\n",
    "    h_nodes = h_item[nodes]\n",
    "    h_center = torch.mean(h_nodes, axis=0)  # 중앙 임베딩 \n",
    "    _, topk = model.kneighbors(h_center.detach().cpu().numpy().reshape(1, -1))\n",
    "        \n",
    "    topk = topk[0]\n",
    "    label = [list(label)[0]]\n",
    "    tp = [x for x in label if x in topk]\n",
    "    if not tp:\n",
    "        hitrates += 0\n",
    "        counts_n += 1\n",
    "    else:\n",
    "        hitrates += 1  # 하나라도 있음\n",
    "        counts_n += 1\n",
    "    \n",
    "hitrate = hitrates / counts_n\n",
    "print(f'\\tHitrate@{k_num}:{hitrate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17453cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "k_num = 500\n",
    "mrr_score = []\n",
    "q_value = 0\n",
    "\n",
    "model = NearestNeighbors(n_neighbors = k_num, \n",
    "                         metric = 'cosine',\n",
    "                        )#cosine\n",
    "model.fit(h_item.detach().cpu().numpy())\n",
    "for i, nodes in tqdm.tqdm(enumerate(item_batch)):\n",
    "    # 실제 유저 ID 탐색\n",
    "    category = nid_uid_dict[i]\n",
    "    user_id = data_dict['user_category'][category]  # 실제 유저 id\n",
    "    label = data_dict['testset'][user_id]  # 테스트 라벨\n",
    "    users.append(user_id)\n",
    "    \n",
    "    item = evaluation.node_to_item(nodes, nid_wid_dict, data_dict['item_category'])  # 와인 ID\n",
    "    \n",
    "    \n",
    "    \n",
    "    label_idx = [i for i, x in enumerate(item) if x in label]  # 라벨 인덱스\n",
    "    nodes = [x for i, x in enumerate(nodes)]\n",
    "    h_nodes = h_item[nodes]\n",
    "    h_center = torch.mean(h_nodes, axis=0)  # 중앙 임베딩 \n",
    "    _, topk = model.kneighbors(h_center.detach().cpu().numpy().reshape(1, -1))\n",
    "        \n",
    "    topk = topk[0]\n",
    "    tp = [x for x in label if x in topk]\n",
    "    \n",
    "    topk = topk.tolist()\n",
    "    \n",
    "    if not tp:\n",
    "        pass\n",
    "    else:\n",
    "        label = list(label)\n",
    "        parents_value = []\n",
    "        for i in range(len(topk)):\n",
    "            try:\n",
    "                parents_value.append(label.index(topk[i]))\n",
    "            except:\n",
    "                pass\n",
    "    try:\n",
    "        mrr_score.append(1/parents_value[0])\n",
    "        q_value += 1\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "mrr = np.round(np.array(mrr_score).sum() / q_value, 3)\n",
    "print(f\"mrr@{k_num} : {mrr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcb12b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = 0#[]\n",
    "hitrates = 0\n",
    "users = []\n",
    "num_labels = 0\n",
    "counts_n = 0\n",
    "mean_recall = []\n",
    "k_num = 10\n",
    "\n",
    "model = NearestNeighbors(n_neighbors = k_num, \n",
    "                         metric = 'cosine',\n",
    "                        )#cosine\n",
    "model.fit(h_item.detach().cpu().numpy())\n",
    "for i, nodes in tqdm.tqdm(enumerate(item_batch)):\n",
    "    # 실제 유저 ID 탐색\n",
    "    category = nid_uid_dict[i]\n",
    "    user_id = data_dict['user_category'][category]  # 실제 유저 id\n",
    "    label = data_dict['testset'][user_id]  # 테스트 라벨\n",
    "    users.append(user_id)\n",
    "    \n",
    "    sort_item = rate_data.loc[(rate_data[\"user\"] == user_id), \"item\"].values.tolist()\n",
    "    sort_idx = [i for i, x in enumerate(sort_item) if x in list(label)]\n",
    "    label = [x for i, x in enumerate(sort_item)if i in sort_idx]\n",
    "    \n",
    "    item = evaluation.node_to_item(nodes, nid_wid_dict, data_dict['item_category'])  # 와인 ID\n",
    "    #label_idx = [i for i, x in enumerate(item) if x in label]  # 라벨 인덱스\n",
    "    #nodes = [x for i, x in enumerate(nodes)if i not in label_idx]  # 라벨 인덱스 미포함 입력 학습용 노드\n",
    "    nodes = [x for i, x in enumerate(nodes)]\n",
    "    h_nodes = h_item[nodes]\n",
    "    h_center = torch.mean(h_nodes, axis=0)  # 중앙 임베딩 \n",
    "    _, topk = model.kneighbors(h_center.detach().cpu().numpy().reshape(1, -1))\n",
    "        \n",
    "    topk = topk[0]\n",
    "    #print(\"라벨 : \",label)\n",
    "    tp = [x for x in label if x in topk]\n",
    "    topk = topk.tolist()\n",
    "    #print(\"맞춘거 : \" , tp)\n",
    "    if not tp:\n",
    "        pass\n",
    "    else:\n",
    "        label = list(label)\n",
    "        parents_value = []\n",
    "        for i in range(len(topk)):\n",
    "            try:\n",
    "                parents_value.append(label.index(topk[i]))\n",
    "            except:\n",
    "                pass\n",
    "    try:\n",
    "        if not tp:\n",
    "            #print(\"------\")\n",
    "            pass\n",
    "        else:\n",
    "            #print(\"맞춘거 최초 인덱스 : \", parents_value[0]+1)\n",
    "            #print(\"------\")\n",
    "            mrr_score.append(1/(parents_value[0]+1))\n",
    "            q_value += 1\n",
    "    except:\n",
    "        continue\n",
    "mrr = np.round(np.array(mrr_score).sum() / q_value, 3)\n",
    "print(f\"mrr@{k_num} : {mrr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70908991",
   "metadata": {},
   "source": [
    "### KDtree 방법으로 했을 시 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0cab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = 0#[]\n",
    "users = []\n",
    "num_labels = 0\n",
    "mean_recall = []\n",
    "k_num = 10\n",
    "\n",
    "tree = spatial.KDTree(h_item.tolist())\n",
    "for i, nodes in tqdm.tqdm(enumerate(item_batch)):\n",
    "    \n",
    "    # 실제 유저 ID 탐색\n",
    "    category = nid_uid_dict[i]\n",
    "    user_id = data_dict['user_category'][category]  # 실제 유저 id\n",
    "    label = data_dict['testset'][user_id]  # 테스트 라벨\n",
    "    users.append(user_id)\n",
    "    \n",
    "    # 실제 와인 ID 탐색\n",
    "    item = evaluation.node_to_item(nodes, nid_wid_dict, data_dict['item_category'])  # 와인 ID\n",
    "    label_idx = [i for i, x in enumerate(item) if x in label]  # 라벨 인덱스\n",
    "    # 아이템 추천\n",
    "    #nodes = [x for i, x in enumerate(nodes)if i not in label_idx]  # 라벨 인덱스 미포함 입력 학습용 노드\n",
    "    nodes = [x for i, x in enumerate(nodes)]  # 라벨 인덱스 미포함 입력 학습용 노드\n",
    "    h_nodes = h_item[nodes]\n",
    "    h_center = torch.mean(h_nodes, axis=0)  # 중앙 임베딩 \n",
    "    if k_num == 1 :\n",
    "        topk = [tree.query(h_center.tolist(), 1)[1]]\n",
    "    else:\n",
    "        topk = tree.query(h_center.tolist(), k_num)[1]\n",
    "    tp = [x for x in label if x in topk]\n",
    "    if not tp:\n",
    "        recalls += 0\n",
    "    else:\n",
    "        mean_recall.append(len(tp)/len(label))\n",
    "        recalls += len(tp)\n",
    "        num_labels += len(label)\n",
    "    \n",
    "recall = np.mean(np.array(mean_recall))#recalls / num_labels\n",
    "recall2 = recalls / num_labels\n",
    "print(f'\\tRecall@{k_num}:{recall}')\n",
    "print(f'\\tRecall@{k_num}:{recall2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b731836",
   "metadata": {},
   "outputs": [],
   "source": [
    "hitrates = 0\n",
    "users = []\n",
    "counts_n = 0\n",
    "k_num = 500\n",
    "\n",
    "tree = spatial.KDTree(h_item.tolist())\n",
    "for i, nodes in tqdm.tqdm(enumerate(item_batch)):\n",
    "    \n",
    "    # 실제 유저 ID 탐색\n",
    "    category = nid_uid_dict[i]\n",
    "    user_id = data_dict['user_category'][category]  # 실제 유저 id\n",
    "    label = data_dict['testset'][user_id]  # 테스트 라벨\n",
    "    users.append(user_id)\n",
    "    \n",
    "    # 실제 와인 ID 탐색\n",
    "    item = evaluation.node_to_item(nodes, nid_wid_dict, data_dict['item_category'])  # 와인 ID\n",
    "    label_idx = [i for i, x in enumerate(item) if x in label]  # 라벨 인덱스\n",
    "    # 아이템 추천\n",
    "    #nodes = [x for i, x in enumerate(nodes)if i not in label_idx]  # 라벨 인덱스 미포함 입력 학습용 노드\n",
    "    nodes = [x for i, x in enumerate(nodes)if i not in label_idx]  # 라벨 인덱스 미포함 입력 학습용 노드\n",
    "    h_nodes = h_item[nodes]\n",
    "    h_center = torch.mean(h_nodes, axis=0)  # 중앙 임베딩 \n",
    "    if k_num == 1 :\n",
    "        topk = [tree.query(h_center.tolist(), 1)[1]]\n",
    "    else:\n",
    "        topk = tree.query(h_center.tolist(), k_num)[1]\n",
    "    tp = [x for x in label if x in topk]\n",
    "    if not tp:\n",
    "        hitrates += 0\n",
    "        counts_n += 1\n",
    "    else:\n",
    "        hitrates += 1  # 하나라도 있음\n",
    "        counts_n += 1\n",
    "    \n",
    "hitrate = hitrates / counts_n\n",
    "print(f'\\tHitrate@{k_num}:{hitrate}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cb8003",
   "metadata": {},
   "source": [
    "# pair data 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d053a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./output/pair_df.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7088d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = df.groupby(['item_id'])['pos_pair'].apply(','.join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0d0735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strTolst(x):\n",
    "    try:\n",
    "        return ast.literal_eval(str(x))   \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "\n",
    "ddf['pos_pair'] = ddf[\"pos_pair\"].apply(lambda x: strTolst(x))\n",
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaddcaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in tqdm.tqdm(range(len(ddf))):\n",
    "    try:\n",
    "        ddf[\"pos_pair\"][i] = sum(ddf[\"pos_pair\"][i] , [])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b45848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ramdom_sampling_list(x, seed=225):\n",
    "    try:\n",
    "        random.seed(seed)\n",
    "        return random.sample(x, 10)   \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "\n",
    "sample_df = ddf.copy()\n",
    "sample_df[\"pos_pair\"] = sample_df[\"pos_pair\"].apply(lambda x: ramdom_sampling_list(x, 329))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8111a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = 0#[]\n",
    "hitrates = 0\n",
    "users = []\n",
    "num_labels = 0\n",
    "counts_n = 0\n",
    "k_num = 10\n",
    "\n",
    "data_form = ddf.copy()\n",
    "data_form[\"labels\"] = 0\n",
    "mean_recall = []\n",
    "\n",
    "model = NearestNeighbors(n_neighbors = k_num, \n",
    "                         metric = 'cosine',\n",
    "                        )#cosine\n",
    "model.fit(h_item.detach().cpu().numpy())\n",
    "for itm in tqdm.tqdm(data_form.item_id.values.tolist()):\n",
    "    label = data_form.loc[data_form.item_id == itm, \"pos_pair\"].values[0]\n",
    "    h_nodes = h_item[itm]\n",
    "    _, topk = model.kneighbors(h_nodes.detach().cpu().numpy().reshape(1, -1))    \n",
    "    topk = topk[0]\n",
    "    tp = [x for x in label if x in topk]\n",
    "    data_form.loc[data_form.item_id == itm,\"labels\"] = str(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef04c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = 0#[]\n",
    "hitrates = 0\n",
    "users = []\n",
    "num_labels = 0\n",
    "counts_n = 0\n",
    "k_num = 10\n",
    "\n",
    "data_form = ddf.copy()\n",
    "\n",
    "mean_recall = []\n",
    "\n",
    "model = NearestNeighbors(n_neighbors = k_num, \n",
    "                         metric = 'cosine',\n",
    "                        )#cosine\n",
    "model.fit(h_item.detach().cpu().numpy())\n",
    "for itm in tqdm.tqdm(data_form.item_id.values.tolist()):\n",
    "    label = data_form.loc[data_form.item_id == itm, \"pos_pair\"].values[0]\n",
    "    h_nodes = h_item[itm]\n",
    "    _, topk = model.kneighbors(h_nodes.detach().cpu().numpy().reshape(1, -1))    \n",
    "    topk = topk[0]\n",
    "    tp = [x for x in label if x in topk]\n",
    "    print(label)\n",
    "    print(topk)\n",
    "    print()\n",
    "    print(tp)\n",
    "    print()\n",
    "    print()\n",
    "    if not tp:\n",
    "        hitrates += 0\n",
    "        counts_n += 1\n",
    "        recalls += 0\n",
    "    else:\n",
    "        mean_recall.append(len(tp)/len(label))\n",
    "        recalls += len(tp)\n",
    "        num_labels += len(label)\n",
    "        hitrates += 1  # 하나라도 있음\n",
    "        counts_n += 1\n",
    "hitrate = hitrates / counts_n\n",
    "recall = np.mean(np.array(mean_recall))#recalls / num_labels\n",
    "print(f'\\tRecall:{recall}\\tHitrate:{hitrate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c990f278",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = 0#[]\n",
    "hitrates = 0\n",
    "users = []\n",
    "num_labels = 0\n",
    "counts_n = 0\n",
    "k_num = 10\n",
    "\n",
    "data_form = ddf.copy()\n",
    "\n",
    "mean_recall = []\n",
    "\n",
    "model = NearestNeighbors(n_neighbors = k_num, \n",
    "                         metric = 'cosine',\n",
    "                        )#cosine\n",
    "model.fit(h_item.detach().cpu().numpy())\n",
    "for itm in tqdm.tqdm(data_form.item_id.values.tolist()):\n",
    "    label = data_form.loc[data_form.item_id == itm, \"pos_pair\"].values[0]\n",
    "    h_nodes = h_item[itm]\n",
    "    _, topk = model.kneighbors(h_nodes.detach().cpu().numpy().reshape(1, -1))    \n",
    "    topk = topk[0]\n",
    "    tp = [x for x in label if x in topk]\n",
    "    if not tp:\n",
    "        hitrates += 0\n",
    "        counts_n += 1\n",
    "        recalls += 0\n",
    "    else:\n",
    "        mean_recall.append(len(tp)/len(label))\n",
    "        recalls += len(tp)\n",
    "        num_labels += len(label)\n",
    "        hitrates += 1  # 하나라도 있음\n",
    "        counts_n += 1\n",
    "hitrate = hitrates / counts_n\n",
    "recall = np.mean(np.array(mean_recall))#recalls / num_labels\n",
    "print(f'\\tRecall:{recall}\\tHitrate:{hitrate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57028950",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = 0#[]\n",
    "hitrates = 0\n",
    "users = []\n",
    "num_labels = 0\n",
    "counts_n = 0\n",
    "mean_recall = []\n",
    "k_num = 10\n",
    "tree = spatial.KDTree(h_item.tolist())\n",
    "for itm in tqdm.tqdm(ddf.item_id.values.tolist()):\n",
    "    label = ddf.loc[ddf.item_id == itm, \"pos_pair\"].values[0]\n",
    "    h_nodes = h_item[itm]\n",
    "    topk = tree.query(h_nodes.tolist(), k_num)[1]\n",
    "    tp = [x for x in label if x in topk]\n",
    "    if not tp:\n",
    "        hitrates += 0\n",
    "        counts_n += 1\n",
    "        recalls += 0\n",
    "    else:\n",
    "        mean_recall.append(len(tp)/len(label))\n",
    "        recalls += len(tp)\n",
    "        num_labels += len(label)\n",
    "        hitrates += 1  # 하나라도 있음\n",
    "        counts_n += 1\n",
    "    \n",
    "hitrate = hitrates / counts_n\n",
    "recall = recalls / num_labels\n",
    "print(np.mean(np.array(mean_recall)))\n",
    "print(f'\\tRecall:{recall}\\tHitrate:{hitrate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571b178f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinsage",
   "language": "python",
   "name": "pinsage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
